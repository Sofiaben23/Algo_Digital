---
title: "Vaud+ Commentaires traduits"
format: html
editor: visual
---

```{r}
library(tidyverse)
library(data.table)
library(ggplot2)
library(lubridate)
library(readxl)
library(knitr)
library(rmarkdown)
library(stringr)
library(forcats)
library(here)
library(plotly)
```

#Visualize data

```{r}
#convert the excel into a csv file
#comm_traduits_xlsx <- read_excel("data/Booking VD traduit.xlsx")
#write.csv(comm_traduits_xlsx, "data/Booking VD traduit.csv", row.names = FALSE)
```

```{r}
comm_booking <- read.csv("data/Booking VD traduit.csv")
```

```{r}
#give an index to each observation
comm_booking <- comm_booking %>%
  mutate(id = row_number()) %>%
  select(id, everything())
```

##Valeurs manquantes

```{r}
# Compter le nombre de NA dans la colonne 'Contenu.positif'
nombre_de_na1 <- sum(is.na(comm_booking$Contenu.positif))
nombre_de_na2 <- sum(is.na(comm_booking$Contenu.négatif))

# Afficher le nombre de NA
print(nombre_de_na1)
print(nombre_de_na2)

```

##Types de voyageurs qui laissent des commentaires

```{r}
# Filtrer les lignes où les commentaires positifs et négatifs sont simultanément vides
comm_booking1 <- comm_booking %>%
  filter(!(is.na(Contenu.positif) | Contenu.positif == "") | 
         !(is.na(Contenu.négatif) | Contenu.négatif == ""))

# Créer un résumé des données
commentaires_par_type <- comm_booking1 %>%
  group_by(Type) %>%
  summarise(Nombre_de_commentaires = n()) %>%
  arrange(desc(Nombre_de_commentaires))

# Calculer le nombre total de commentaires
total_commentaires <- sum(commentaires_par_type$Nombre_de_commentaires)

# Ajouter une colonne de pourcentages
commentaires_par_type <- commentaires_par_type %>%
  mutate(Pourcentage = (Nombre_de_commentaires / total_commentaires) * 100)

ggplot(commentaires_par_type, aes(x = reorder(Type, -Pourcentage), y = Pourcentage, fill = Type)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(x = "Type", y = "Pourcentage de Commentaires", title = "Pourcentage de Commentaires par Type de voyageurs") +
  coord_flip()  # Rend les étiquettes des pays plus lisibles

```

##D'où viennent les voyageurs qui laissent le plus de commentaires

*Top 10*

```{r}

# Compter le nombre de commentaires par pays
commentaires_par_pays <- comm_booking %>%
  group_by(Pays) %>%
  summarise(Nombre_de_commentaires = n())

# Calculer le nombre total de commentaires
total_commentaires <- sum(commentaires_par_pays$Nombre_de_commentaires)

# Ajouter une colonne de pourcentages
commentaires_par_pays <- commentaires_par_pays %>%
  mutate(Pourcentage = (Nombre_de_commentaires / total_commentaires) * 100)

# Sélectionner les 10 pays principaux
top_pays <- commentaires_par_pays %>%
  arrange(desc(Nombre_de_commentaires)) %>%
  top_n(10, Nombre_de_commentaires)

# Créer un graphique à barres montrant le pourcentage pour les 10 pays principaux
ggplot(top_pays, aes(x = reorder(Pays, -Pourcentage), y = Pourcentage, fill = Pays)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(x = "Pays", y = "Pourcentage de Commentaires", title = "Pourcentage de Commentaires par Pays pour les 10 Pays Principaux") +
  coord_flip()  # Rend les étiquettes des pays plus lisibles
```

##Pourcentage de chaque type de voyageur, en permettant un zoom par pays

```{r}
# Calculer le nombre de commentaires par type de voyageur et par pays
type_voyageur_par_pays <- comm_booking %>%
  group_by(Pays, Type) %>%
  summarise(Nombre_de_commentaires = n(), .groups = 'drop')

# Identifier les 10 pays avec le plus grand nombre de commentaires
top_pays <- type_voyageur_par_pays %>%
  group_by(Pays) %>%
  summarise(Total_commentaires = sum(Nombre_de_commentaires)) %>%
  top_n(10, Total_commentaires) %>%
  pull(Pays)

# Filtrer le dataset pour ne garder que les 10 premiers pays
data_top_pays <- type_voyageur_par_pays %>%
  filter(Pays %in% top_pays)

# Calculer le total de commentaires pour ces pays
total_par_pays <- data_top_pays %>%
  group_by(Pays) %>%
  summarise(Total_commentaires = sum(Nombre_de_commentaires), .groups = 'drop')

# Joindre les données pour obtenir les pourcentages
data_pourcentage <- data_top_pays %>%
  inner_join(total_par_pays, by = "Pays") %>%
  mutate(Pourcentage = (Nombre_de_commentaires / Total_commentaires) * 100)

data_pourcentage_plot <- data_pourcentage %>% 
  ggplot(aes(x = Pays, y = Pourcentage, fill = Type)) + 
  geom_bar(stat = "identity") +
  theme_minimal()


plot_ly(data = data_pourcentage, x = ~Pays, y=~Pourcentage, type = "bar", color = ~Type)
```

#Pretraitement de texte 1. Mettre tous les mots en minuscule 2. Enlever toutes la ponctuations 3. Faire des n-gram (1,2 et 3) 4. Faire une intersection entre les mots/listes de mots les plus utilisés selon les types 5. Faire des clusters: quelles expressions sont les plus utilisées selon les types - ex: mots utilisés chez les couples - intersection avec les autres types de voyageurs

*Nouveau data set pour la tokenisation*

```{r}
# Créer un sous-ensemble de données avec seulement certaines colonnes
subset_comments <- select(comm_booking, id, Contenu.positif, Contenu.négatif)
```

##Tokenisation 1-gram sans les stopwords *Contenu négatif*

```{r}
library(tidytext)
library(tm)

french_stopwords <- stopwords("french")

# Tokenisation de la colonne Contenu.négatif
tokens_negatif <- subset_comments %>%
  unnest_tokens(word, Contenu.négatif, token = "words")


tokens_negatif$Contenu.positif <- NULL

# Retirer les stopwords français
tokens_negatif <- tokens_negatif %>%
  filter(!word %in% french_stopwords)
```

*Contenu positif*

```{r}
tokens_positif <- subset_comments%>%
  unnest_tokens(word, Contenu.positif, token="words")

tokens_positif$Contenu.négatif<- NULL

# Retirer les stopwords français
tokens_positif <- tokens_positif %>%
  filter(!word %in% french_stopwords)
```

##2-gram

*Contenu négatif*

```{r}
#bigram negatif
bigram_negatif <- subset_comments %>%
  unnest_tokens(bigram, Contenu.négatif, token = "ngrams", n=2)
bigram_negatif$Contenu.positif<-NULL

# Séparation des bigrams en deux colonnes
bigram_negatif <- bigram_negatif %>%
  separate(bigram, into = c("word1", "word2"), sep = " ")

# Filtrage des bigrams pour enlever ceux contenant un stopword
bigram_negatif <- bigram_negatif %>%
  filter(!word1 %in% french_stopwords & !word2 %in% french_stopwords)

# Recombinaison des mots pour reformer les bigrams nettoyés
bigram_negatif <- bigram_negatif %>%
  unite(bigram, word1, word2, sep = " ")

count_negatif_bigram <- bigram_negatif%>%
  count(bigram, sort = TRUE)

print(count_negatif_bigram)
```

*Contenu positif*

```{r}
#bigram positif
bigram_positif <- subset_comments %>%
  unnest_tokens(bigram, Contenu.positif, token = "ngrams", n=2)
bigram_positif$Contenu.négatif<-NULL

# Séparation des bigrams en deux colonnes
bigram_positif <- bigram_positif %>%
  separate(bigram, into = c("word1", "word2"), sep = " ")

# Filtrage des bigrams pour enlever ceux contenant un stopword
bigram_positif <- bigram_positif %>%
  filter(!word1 %in% french_stopwords & !word2 %in% french_stopwords)

# Recombinaison des mots pour reformer les bigrams nettoyés
bigram_positif <- bigram_positif %>%
  unite(bigram, word1, word2, sep = " ")

count_positif_bigram <- bigram_positif%>%
  count(bigram, sort = TRUE)

print(count_positif_bigram)
```

##3-gram

*Contenu négatif*

```{r}
#trigram negatif
trigram_negatif <- subset_comments %>%
  unnest_tokens(trigram, Contenu.négatif, token = "ngrams", n=3)
trigram_negatif$Contenu.positif<-NULL

# Séparation des trigrams en trois mots
trigram_negatif <- trigram_negatif %>%
  separate(trigram, into = c("word1", "word2", "word3"), sep = " ", extra = "merge")

# Filtrage pour enlever les lignes contenant des stopwords dans l'un des trois mots
trigram_negatif <- trigram_negatif %>%
  filter(!word1 %in% french_stopwords & !word2 %in% french_stopwords & !word3 %in% french_stopwords)

# Recombinaison des mots pour reformer les trigrams nettoyés
trigram_negatif <- trigram_negatif %>%
  unite(trigram, word1, word2, word3, sep = " ")

count_negatif_trigram <- trigram_negatif%>%
  count(trigram, sort = TRUE)

print(count_negatif_trigram)

```

*Contenu positif*

```{r}
#trigram positif
trigram_positif <- subset_comments %>%
  unnest_tokens(trigram, Contenu.positif, token = "ngrams", n=3)
trigram_positif$Contenu.négatif <-NULL

# Séparation des trigrams en trois mots
trigram_positif <- trigram_positif %>%
  separate(trigram, into = c("word1", "word2", "word3"), sep = " ", extra = "merge")

# Filtrage pour enlever les lignes contenant des stopwords dans l'un des trois mots
trigram_positif <- trigram_positif %>%
  filter(!word1 %in% french_stopwords & !word2 %in% french_stopwords & !word3 %in% french_stopwords)

# Recombinaison des mots pour reformer les trigrams nettoyés
trigram_positif <- trigram_positif %>%
  unite(trigram, word1, word2, word3, sep = " ")

count_positif_trigram <- trigram_positif %>%
  count(trigram, sort = TRUE)

print(count_positif_trigram)
```

##4-gram

*Contenu négatif*

```{r}
fourgram_negatif <- subset_comments %>%
  unnest_tokens(fourgram, Contenu.négatif, token = "ngrams", n=4)
fourgram_negatif$Contenu.positif<-NULL

# Séparation des trigrams en trois mots
fourgram_negatif <- fourgram_negatif %>%
  separate(fourgram, into = c("word1", "word2", "word3", "word4"), sep = " ", extra = "merge")

# Filtrage pour enlever les lignes contenant des stopwords dans l'un des trois mots
fourgram_negatif <- fourgram_negatif %>%
  filter(!word1 %in% french_stopwords & !word2 %in% french_stopwords & !word3 %in% french_stopwords & !word4 %in% french_stopwords)

# Recombinaison des mots pour reformer les trigrams nettoyés
fourgram_negatif <- fourgram_negatif %>%
  unite(fourgram, word1, word2, word3, word4, sep = " ")

count_negatif_fourgram <- fourgram_negatif%>%
  count(fourgram, sort = TRUE)

print(count_negatif_fourgram)
```

*Contenu positif*

```{r}
fourgram_positif <- subset_comments %>%
  unnest_tokens(fourgram, Contenu.positif, token = "ngrams", n=4)
fourgram_positif$Contenu.négatif<-NULL

# Séparation des trigrams en trois mots
fourgram_positif <- fourgram_positif %>%
  separate(fourgram, into = c("word1", "word2", "word3", "word4"), sep = " ", extra = "merge")

# Filtrage pour enlever les lignes contenant des stopwords dans l'un des trois mots
fourgram_positif <- fourgram_positif %>%
  filter(!word1 %in% french_stopwords & !word2 %in% french_stopwords & !word3 %in% french_stopwords & !word4 %in% french_stopwords)

# Recombinaison des mots pour reformer les trigrams nettoyés
fourgram_positif <- fourgram_positif %>%
  unite(fourgram, word1, word2, word3, word4, sep = " ")

count_positif_fourgram <- fourgram_positif%>%
  count(fourgram, sort = TRUE)

print(count_positif_fourgram)
```

#Supprimer les faux commentaires négatifs

Code pour nettoyer la ponctuation et normaliser les espaces:

```{r}
# Nettoyer la ponctuation et normaliser les espaces
comm_booking <- comm_booking %>%
  mutate(
    Contenu.positif = str_replace_all(Contenu.positif, "[[:punct:]]", " ") %>%
                      str_replace_all(" +", " "),  # Remplacer multiples espaces par un seul espace
    Contenu.négatif = str_replace_all(Contenu.négatif, "[[:punct:]]", " ") %>%
                      str_replace_all(" +", " ")
  )

```

```{r}
# Transformer les lettres en minuscules pour les colonnes spécifiées
comm_booking <- comm_booking %>%
  mutate(Contenu.positif = tolower(Contenu.positif),
         Contenu.négatif = tolower(Contenu.négatif))
```

*Supprimer les "rien"*

```{r}
# Remplacer les cases contenant "rien" par NA dans 'Contenu.negatif'
comm_booking <- comm_booking %>%
  mutate(Contenu.négatif = case_when(
    str_detect(Contenu.négatif, fixed("rien")) ~ NA_character_,
    TRUE ~ Contenu.négatif
  ))

```

*Supprimer les "tout va bien"*

```{r}

```

##Travailler sur le dataset complet avec les 3-gram

On remarque qu'il est plus pertinent de travailler avec des 3-gram pour le contenu des colonnes de commentaires.

*Contenu positif*

```{r}
# Création des trigrammes à partir des colonnes de texte
#Transformation de la colonne Contenu.positif en trigramm 
#Separation de mots pour supprimer les stopwords
#Rassemblement des mots en trigram 
comm_booking_trigrams_positif <- comm_booking %>%
  unnest_tokens(output = trigram, input = Contenu.positif, token = "ngrams", n = 3) %>%
  separate(trigram, into = c("word1", "word2", "word3"), sep = " ", extra = "merge") %>%
  filter(!word1 %in% french_stopwords & !word2 %in% french_stopwords & !word3 %in% french_stopwords) %>%
  unite(trigram, word1, word2, word3, sep = " ")

```

Fréquence des trigrammes par type de client:

```{r}
#Calculez la fréquence des trigrammes par type de client.
trigram_freq_by_type_positif <- comm_booking_trigrams_positif %>%
  count(Type, trigram, sort = TRUE) %>%
  group_by(Type) %>%
  mutate(freq = n / sum(n))

# Pour identifier les trigrammes distinctifs, comparez la fréquence relative des trigrammes dans chaque groupe
distinctive_trigrams_positif <- trigram_freq_by_type_positif %>%
  group_by(trigram) %>%
  filter(n() > 1) %>%
  mutate(max_freq = max(freq),
         is_distinctive = freq == max_freq) %>%
  filter(is_distinctive) %>%
  ungroup() %>%
  arrange(desc(freq))

# Sélectionner les 10 trigrammes les plus utilisés par type de client
top_trigrams_per_type_positif <- distinctive_trigrams_positif %>%
  group_by(Type) %>%
  slice_max(order_by = freq, n = 10) %>%
  ungroup()

# Visualiser les résultats
ggplot(top_trigrams_per_type_positif, aes(x = reorder(trigram, freq), y = freq, fill = Type)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ Type, scales = "free") +
  coord_flip() +
  labs(x = "Trigram", y = "Relative Frequency", title = "Top 10 Distinctive Trigrams by Client Type") +
  theme_minimal()

```

*Contenu négatif*

```{r}
# Création des trigrammes à partir des colonnes de texte
comm_booking_trigrams_negatif <- comm_booking %>%
  unnest_tokens(output = trigram, input = Contenu.négatif, token = "ngrams", n = 3) %>%
  separate(trigram, into = c("word1", "word2", "word3"), sep = " ", extra = "merge") %>%
  filter(!word1 %in% french_stopwords & !word2 %in% french_stopwords & !word3 %in% french_stopwords) %>%
  unite(trigram, word1, word2, word3, sep = " ")
```

Fréquence des trigrammes par type de client:

```{r}
#Calculez la fréquence des trigrammes par type de client.
trigram_freq_by_type_negatif <- comm_booking_trigrams_negatif %>%
  count(Type, trigram, sort = TRUE) %>%
  group_by(Type) %>%
  mutate(freq = n / sum(n))

# Pour identifier les trigrammes distinctifs, comparez la fréquence relative des trigrammes dans chaque groupe
distinctive_trigrams_negatif <- trigram_freq_by_type_negatif %>%
  group_by(trigram) %>%
  filter(n() > 1) %>%
  mutate(max_freq = max(freq),
         is_distinctive = freq == max_freq) %>%
  filter(is_distinctive) %>%
  ungroup() %>%
  arrange(desc(freq))

# Sélectionner les 10 trigrammes les plus utilisés par type de client
top_trigrams_per_type_negatif <- distinctive_trigrams_negatif %>%
  group_by(Type) %>%
  slice_max(order_by = freq, n = 10) %>%
  ungroup()

# Visualiser les résultats
ggplot(top_trigrams_per_type_negatif, aes(x = reorder(trigram, freq), y = freq, fill = Type)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ Type, scales = "free") +
  coord_flip() +
  labs(x = "Trigram", y = "Relative Frequency", title = "Top 10 Distinctive Negative Trigrams by Client Type") +
  theme_minimal()

```

peut-être mettre les verbes a l'infinitif

Fréquence de trigrammes par pays d'origine: (pas significatif)

```{r, eval=FALSE}
#Calculez la fréquence des trigrammes par type de client.
trigram_freq_by_pays <- comm_booking_trigrams %>%
  count(Pays, trigram, sort = TRUE) %>%
  group_by(Pays) %>%
  mutate(freq = n / sum(n))

# Pour identifier les trigrammes distinctifs, comparez la fréquence relative des trigrammes dans chaque groupe
distinctive_trigrams2 <- trigram_freq_by_pays %>%
  group_by(trigram) %>%
  filter(n() > 1) %>%
  mutate(max_freq = max(freq),
         is_distinctive = freq == max_freq) %>%
  filter(is_distinctive) %>%
  ungroup() %>%
  arrange(desc(freq))

```

###Quel vocabulaire est utilisé par quel type de clientèle

##Tag Cloud
